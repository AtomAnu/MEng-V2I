{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "56e81991b15ac790597f584ddc523a2fa3b2c816d8ca744d0ac1b11c2260d73e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from sympy import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit, least_squares\n",
    "from scipy.optimize import minimize as sp_minimize\n",
    "from scipy import special\n",
    "from lmfit import minimize, Minimizer, Parameters, Parameter, report_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_name, subdir=''):\n",
    "    \"\"\"\n",
    "    Loads data from .csv file in to DataFrame\n",
    "\n",
    "    :param file_name: .csv file name in string\n",
    "    :param subdir: optional parameter to specify the subdirectory of the file\n",
    "    :return: extracted data in DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    file_dir = os.path.realpath('../')\n",
    "    print(file_dir)\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        if root.endswith(subdir):\n",
    "            for name in files:\n",
    "                if name == file_name:\n",
    "                    file_path = os.path.join(root, name)\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_Noise(component = 1):\n",
    "    \"\"\" Inital parameters and bounds for each paramter according to LF (0-0.01Hz)in the paper\n",
    "    \"\"\"\n",
    "    LMparams = Parameters()\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on all 3 components at once\n",
    "\n",
    "    LMparams.add('A1_FS', value = 10.)\n",
    "    LMparams.add('A2_FS', value = 10.)\n",
    "    LMparams.add('A3_FS', value = 10.)\n",
    "    LMparams.add('w1_FS', value = 0, min = 0, max = 0.01*2*math.pi)\n",
    "    LMparams.add('w2_FS', value = 0.005*2*math.pi, min = 0, max = 0.01*2*math.pi)\n",
    "    LMparams.add('w3_FS', value = 0.01*2*math.pi, min = 0, max = 0.01*2*math.pi)\n",
    "    LMparams.add('phi1_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi2_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi3_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on one component at a time\n",
    "\n",
    "    # if component == 1:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0, min = 0, max = 0.01*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 2:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0.005*2*math.pi, min = 0, max = 0.01*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 3:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0.01*2*math.pi, min = 0, max = 0.01*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    return LMparams\n",
    "\n",
    "def MF_Noise(component = 1):\n",
    "    \"\"\" Inital parameters and bounds for each paramter according to MF (0.01-0.25Hz) in the paper\n",
    "    \"\"\"\n",
    "    LMparams = Parameters()\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on all 3 components at once\n",
    "\n",
    "    LMparams.add('A1_FS', value = 10.)\n",
    "    LMparams.add('A2_FS', value = 10.)\n",
    "    LMparams.add('A3_FS', value = 10.)\n",
    "    LMparams.add('w1_FS', value = 0.02*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    LMparams.add('w2_FS', value = 0.03*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    LMparams.add('w3_FS', value = 0.03*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    LMparams.add('phi1_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi2_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi3_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on one component at a time\n",
    "\n",
    "    # if component == 1:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0.02*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 2:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0.03*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 3:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0.03*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    return LMparams\n",
    "\n",
    "def HF_Noise(component = 1):\n",
    "    \"\"\" Inital parameters and bounds for each paramter according to HF (0.25-0.5Hz) in the paper\n",
    "    \"\"\"\n",
    "    LMparams = Parameters()\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on all 3 components at once\n",
    "\n",
    "    LMparams.add('A1_FS', value = 1.)\n",
    "    LMparams.add('A2_FS', value = 1.)\n",
    "    LMparams.add('A3_FS', value = 1.)\n",
    "    LMparams.add('w1_FS', value = 0.25*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    LMparams.add('w2_FS', value = 0.375*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    LMparams.add('w3_FS', value = 0.5*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    LMparams.add('phi1_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi2_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi3_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on one component at a time\n",
    "\n",
    "    # if component == 1:\n",
    "    #     LMparams.add('A_FS', value = 1.)\n",
    "    #     LMparams.add('w_FS', value = 0.25*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 2:\n",
    "    #     LMparams.add('A_FS', value = 1.)\n",
    "    #     LMparams.add('w_FS', value = 0.375*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 3:\n",
    "    #     LMparams.add('A_FS', value = 1.)\n",
    "    #     LMparams.add('w_FS', value = 0.5*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    return LMparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(object):\n",
    "    \"\"\" Module 2: Drive Scenario\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DC(object):\n",
    "    \"\"\" Module 1: Drive Cycle\n",
    "    \"\"\"\n",
    "    def __init__(self, dc_length):\n",
    "        \n",
    "        t_DC = dc_length\n",
    "        sum_t_DS = 0\n",
    "        while t_DC > sum_t_DS:\n",
    "            pass\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Acceleration(object):\n",
    "    def __init__(self):\n",
    "        # self.bins = pd.DataFrame([0.2,0.4,0.6,0.8,1,1.2,1.4,1.6,1.8,2])\n",
    "        # self.data_points = pd.DataFrame([1,4,12,24,20,29,9,1,0,0])\n",
    "        self.bins = pd.DataFrame(np.linspace(0.1, 2.098, num=1000))\n",
    "        self.data_points = pd.DataFrame(np.repeat([1,4,12,24,20,29,9,1,0,0],100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cruising_Duration(object):\n",
    "    def __init__(self):\n",
    "        # self.bins = pd.DataFrame([0,12,24,36,48,60,72,84,96,108,120])\n",
    "        # data_points = pd.DataFrame([3,14,28,26,12,7,2,4,3,0,1])\n",
    "        self.bins = pd.DataFrame(np.linspace(-6, 125.88, num=1100))\n",
    "        self.data_points = pd.DataFrame(np.repeat([3,14,28,26,12,7,2,4,3,0,1],100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Average_Crusing_Speed(object):\n",
    "    def __init__(self):\n",
    "        # self.bins = pd.DataFrame([2,4,6,8,10,12,14,16,18,20])\n",
    "        # self.data_points = pd.DataFrame([0,1,2,6,18,35,22,11,4,1])\n",
    "        self.bins = pd.DataFrame(np.linspace(1, 20.98, num=1000))\n",
    "        self.data_points = pd.DataFrame(np.repeat([0,1,2,6,18,35,22,11,4,1],100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deceleration(object):\n",
    "    def __init__(self):\n",
    "        # self.bins = pd.DataFrame([0,0.5,1,1.5,2,2.5,3,3.5,4,4.5])\n",
    "        # self.data_points = pd.DataFrame([0,0,6,14,22,20,16,13,6,3])\n",
    "        self.bins = pd.DataFrame(np.linspace(-0.25, 4.745, num=1000))\n",
    "        self.data_points = pd.DataFrame(np.repeat([0,0,6,14,22,20,16,13,6,3],100))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_param():\n",
    "    \"\"\" Inital parameters for each Gaussian characteristic paramter \n",
    "    \"\"\"\n",
    "    LMparams = Parameters()\n",
    "    # there are two sets of values because the paper used 2 curve (n=2) to fit the distributions\n",
    "    LMparams.add('alpha_1', value = 1., min = 0)\n",
    "    LMparams.add('alpha_2', value = 1., min = 0)\n",
    "    LMparams.add('sigma_1', value = 1., min = 0)\n",
    "    LMparams.add('sigma_2', value = 1., min = 0)\n",
    "    LMparams.add('meu_1', value = 1., min = 0)\n",
    "    LMparams.add('meu_2', value = 1., min = 0)\n",
    "\n",
    "    return LMparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probability_Functions(object):\n",
    "    def __init__(self, x, y, n):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.original_y = y\n",
    "        # the number of Gaussian distribution used to describe the data\n",
    "        self.n = n\n",
    "\n",
    "    def single_component(self, alpha_i, sigma_i, meu_i):\n",
    "        \"\"\" Returns the single Gaussian component as described in the sum of eqn (10)\n",
    "        \"\"\"\n",
    "        exp_component = -((self.x - meu_i)**2)/(2*(sigma_i**2))\n",
    "        fcn = (alpha_i/(sigma_i*math.sqrt(2*math.pi)))*np.exp(exp_component)\n",
    "        return fcn\n",
    "\n",
    "    def eqn_model(self, params):\n",
    "        \"\"\" Returns the Gaussian component sum as described in eqn (10)\n",
    "        \"\"\"\n",
    "        # runs a loop for the number of of Gaussian distibutions used to describe the data, and sums the single components \n",
    "        for component in range(1,self.n+1):\n",
    "            alpha_i = 'alpha_'+str(component)\n",
    "            sigma_i = 'sigma_'+str(component)\n",
    "            meu_i = 'meu_'+str(component)\n",
    "            if component == 1:\n",
    "                model = self.single_component(params[alpha_i],params[sigma_i],params[meu_i])\n",
    "            else:\n",
    "                model += self.single_component(params[alpha_i],params[sigma_i],params[meu_i])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fnc2min(self, params):\n",
    "        \"\"\" Returns the residuals for eqn_model\n",
    "        \"\"\"\n",
    "        return (self.y - self.eqn_model(params))\n",
    "\n",
    "    def NLLSR(self, LMparams):\n",
    "        \"\"\" Returns the result of the NLLSR using LMFit\n",
    "        \"\"\"\n",
    "        # uses least swuares method to minimize the parameters given by LMparams according to the residuals given by self.fnc2min\n",
    "        LMFitmin = Minimizer(self.fnc2min, LMparams)\n",
    "        LMFitResult = LMFitmin.minimize(method='least_squares')\n",
    "        lmfit.printfuncs.report_fit(LMFitResult.params)\n",
    "        self.params = LMFitResult.params\n",
    "\n",
    "        return LMFitResult\n",
    "\n",
    "    def single_cdf_component(self, x, alpha_i, sigma_i, meu_i):\n",
    "        \"\"\" Returns the single cdf component as described in the sum of eqn (12)\n",
    "        \"\"\"\n",
    "        erf_param = (x - meu_i)/(sigma_i * math.sqrt(2))\n",
    "        answer =  0.5 * alpha_i * (1 + special.erf(erf_param))\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def cdf(self, x, params):\n",
    "        \"\"\" Returns the cdf component sum as described in eqn (12)\n",
    "        \"\"\"\n",
    "        for component in range(1,self.n+1):\n",
    "            alpha_i = 'alpha_'+str(component)\n",
    "            sigma_i = 'sigma_'+str(component)\n",
    "            meu_i ='meu_'+str(component)\n",
    "\n",
    "            if component == 1:\n",
    "                answer =  self.single_cdf_component(x, params[alpha_i], params[sigma_i], params[meu_i])\n",
    "            else:\n",
    "                answer +=  self.single_cdf_component(x, params[alpha_i], params[sigma_i], params[meu_i])\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def normalised_cdf(self,x, LMparams):\n",
    "        \"\"\" Returns a normalised cdf as described in eqn (13)\n",
    "        \"\"\"\n",
    "        lim_inf_cdf = self.cdf(math.inf, LMparams)\n",
    "        answer = self.cdf(x, LMparams)/lim_inf_cdf\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def normalised_single_cdf(self,x, alpha_i, sigma_i, meu_i):\n",
    "        \"\"\" normalised cdf for a SINGLE component \n",
    "        \"\"\"\n",
    "        lim_inf_cdf = self.single_cdf_component(math.inf, alpha_i, sigma_i, meu_i)\n",
    "        answer = self.single_cdf_component(x, alpha_i, sigma_i, meu_i)/lim_inf_cdf\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def single_quantile_component(self, p, alpha_i, sigma_i, meu_i):\n",
    "        \"\"\" single inverse cdf component\n",
    "        \"\"\"\n",
    "        inv_erf_param = (2*p/alpha_i) - 1\n",
    "        answer =  meu_i + (sigma_i * math.sqrt(2) * special.erfinv(inv_erf_param))\n",
    "\n",
    "        return answer\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inv_cdf(object):\n",
    "    def __init__(self, prob_obj):\n",
    "        # create a numpy array ranging from 0 to 1 with granularity of e-3\n",
    "        # the array represents the possible p values that could be input to determine the attribute value, therefore\n",
    "        # granularity of the random number generator needs to be set to e-3\n",
    "        self.x = np.arange(0,1.001,0.001)\n",
    "        # genenrate an empty array with same shape as self.x\n",
    "        self.y = np.zeros(self.x.shape)\n",
    "        # save a local version of the probability object\n",
    "        self.prob_obj = prob_obj\n",
    "        # generate the lookup table for the ranges of x\n",
    "        self.fit()\n",
    "\n",
    "    def diff(self, x, a):\n",
    "        \"\"\" residual(?) for the fit method\n",
    "        \"\"\"\n",
    "        yt = self.prob_obj.normalised_cdf(x, self.prob_obj.params)\n",
    "        return (yt - a )**2\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\" Fits the inverse normalised cdf and generates a lookup table of sort\n",
    "        \"\"\"\n",
    "        # the for loop generates a lookup table correlating x and y based on the normalised cdf\n",
    "        for idx,x_value in enumerate(self.x):\n",
    "            res = sp_minimize(self.diff, 1.0, args=(x_value), method='Nelder-Mead', tol=1e-6)\n",
    "            self.y[idx] = res.x[0]\n",
    "\n",
    "    def get_value(self, p):\n",
    "        \"\"\" Gives corresponding attribute value depending on p (ranging from 0 to 1)\n",
    "        \"\"\"\n",
    "        x_copy = np.copy(self.x)\n",
    "        # find the index at which the x is equal to the input p\n",
    "        index = np.where(x_copy == p)\n",
    "        # gets the corresponding attribute value depending on the index\n",
    "        value = self.y[index]\n",
    "\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object storing histogram datapoints\n",
    "accel_obj = Acceleration()\n",
    "print(accel_obj.bins)\n",
    "#load initial gaussian parameters\n",
    "param_obj = Gaussian_param()\n",
    "#create a probability function object for acceleration with its acceleration histogram data\n",
    "accel_prob_obj = Probability_Functions(accel_obj.bins, accel_obj.data_points,2)\n",
    "#fit the histogram\n",
    "hey = accel_prob_obj.NLLSR(param_obj)\n",
    "\n",
    "#plot the histogram, each gaussian component and the combined gaussian curve\n",
    "plt.plot(accel_prob_obj.x,accel_prob_obj.original_y,'b')\n",
    "yy = accel_prob_obj.eqn_model(hey.params)\n",
    "gaus_1 = accel_prob_obj.single_component(hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])\n",
    "gaus_2 = accel_prob_obj.single_component(hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])\n",
    "plt.plot(accel_prob_obj.x, yy,'r', label = 'best_fit')\n",
    "plt.plot(accel_prob_obj.x, gaus_1,'g', label = 'gaus_1')\n",
    "plt.plot(accel_prob_obj.x, gaus_2,'y', label = 'gaus_2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(accel_prob_obj.cdf(0.8, hey.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.33\n",
    "erf_param = (x - 0.83011822)/(0.21988047 * math.sqrt(2))\n",
    "print(erf_param)\n",
    "answer =  12.5916156 * (1 + special.erf(erf_param))\n",
    "print(answer)\n",
    "\n",
    "x = math.inf\n",
    "erf_param = (x - 0.83011822)/(0.21988047 * math.sqrt(2))\n",
    "print(erf_param)\n",
    "lim =  12.5916156 * (1 + special.erf(erf_param))\n",
    "print(answer/lim)\n",
    "\n",
    "\n",
    "x = np.linspace(0,2,1000)\n",
    "#plot the cdf of the sum of gaussian\n",
    "lim_inf_cdf = accel_prob_obj.cdf(math.inf, hey.params)\n",
    "yy = accel_prob_obj.normalised_cdf(x,hey.params)\n",
    "cdf_1 = accel_prob_obj.single_cdf_component(x,hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])/lim_inf_cdf\n",
    "cdf_2 = accel_prob_obj.single_cdf_component(x,hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])/lim_inf_cdf\n",
    "plt.plot(yy,x,'r', label = 'best_fit')\n",
    "plt.plot(cdf_1,x,'g', label = 'cdf_1')\n",
    "plt.plot(cdf_2,x,'y', label = 'cdf_2')\n",
    "plt.legend(loc='best')\n",
    "# plt.show()\n",
    "\n",
    "inv_cdf_obj = inv_cdf(accel_prob_obj)\n",
    "print(inv_cdf_obj.get_value(0))\n",
    "\n",
    "print(accel_prob_obj.normalised_cdf(0.718,hey.params))\n",
    "\n",
    "# q_1 = accel_prob_obj.single_quantile_component(x*lim_inf_cdf,hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])\n",
    "# q_2 = accel_prob_obj.single_quantile_component(x*lim_inf_cdf,hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])\n",
    "\n",
    "plt.plot(inv_cdf_obj.x,inv_cdf_obj.y,  label = 'minimized')\n",
    "# plt.plot(x,q_1,label = 'idk_1')\n",
    "# plt.plot(x,q_2,label = 'idk_2')\n",
    "plt.title(r'$f^{-1}(x)$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(loc='best')\n",
    "# # plt.savefig(\"function_inverse.png\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object storing histogram datapoints\n",
    "cd_obj = Cruising_Duration()\n",
    "print(cd_obj.bins)\n",
    "#load initial gaussian parameters\n",
    "param_obj = Gaussian_param()\n",
    "#create a probability function object for acceleration with its acceleration histogram data\n",
    "cd_prob_obj = Probability_Functions(cd_obj.bins, cd_obj.data_points,2)\n",
    "#fit the histogram\n",
    "hey = cd_prob_obj.NLLSR(param_obj)\n",
    "\n",
    "#plot the histogram, each gaussian component and the combined gaussian curve\n",
    "plt.plot(cd_prob_obj.x,cd_prob_obj.original_y,'b')\n",
    "yy = cd_prob_obj.eqn_model(hey.params)\n",
    "gaus_1 = cd_prob_obj.single_component(hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])\n",
    "gaus_2 = cd_prob_obj.single_component(hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])\n",
    "plt.plot(cd_prob_obj.x, yy,'r', label = 'best_fit')\n",
    "plt.plot(cd_prob_obj.x, gaus_1,'g', label = 'gaus_1')\n",
    "plt.plot(cd_prob_obj.x, gaus_2,'y', label = 'gaus_2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object storing histogram datapoints\n",
    "avg_cs_obj = Average_Crusing_Speed()\n",
    "print(avg_cs_obj.bins)\n",
    "#load initial gaussian parameters\n",
    "param_obj = Gaussian_param()\n",
    "#create a probability function object for acceleration with its acceleration histogram data\n",
    "avg_cs_prob_obj = Probability_Functions(avg_cs_obj.bins, avg_cs_obj.data_points,2)\n",
    "#fit the histogram\n",
    "hey = avg_cs_prob_obj.NLLSR(param_obj)\n",
    "\n",
    "#plot the histogram, each gaussian component and the combined gaussian curve\n",
    "plt.plot(avg_cs_prob_obj.x,avg_cs_prob_obj.original_y,'b')\n",
    "yy = avg_cs_prob_obj.eqn_model(hey.params)\n",
    "gaus_1 = avg_cs_prob_obj.single_component(hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])\n",
    "gaus_2 = avg_cs_prob_obj.single_component(hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])\n",
    "plt.plot(avg_cs_prob_obj.x, yy,'r', label = 'best_fit')\n",
    "plt.plot(avg_cs_prob_obj.x, gaus_1,'g', label = 'gaus_1')\n",
    "plt.plot(avg_cs_prob_obj.x, gaus_2,'y', label = 'gaus_2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object storing histogram datapoints\n",
    "decel_obj = Deceleration()\n",
    "print(decel_obj.bins)\n",
    "#load initial gaussian parameters\n",
    "param_obj = Gaussian_param()\n",
    "#create a probability function object for deceleration with its deceleration histogram data\n",
    "decel_prob_obj = Probability_Functions(decel_obj.bins, decel_obj.data_points,2)\n",
    "#fit the histogram\n",
    "hey = decel_prob_obj.NLLSR(param_obj)\n",
    "\n",
    "#plot the histogram, each gaussian component and the combined gaussian curve\n",
    "plt.plot(decel_prob_obj.x,decel_prob_obj.original_y,'b')\n",
    "yy = decel_prob_obj.eqn_model(hey.params)\n",
    "gaus_1 = decel_prob_obj.single_component(hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])\n",
    "gaus_2 = decel_prob_obj.single_component(hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])\n",
    "plt.plot(decel_prob_obj.x, yy,'r', label = 'best_fit')\n",
    "plt.plot(decel_prob_obj.x, gaus_1,'g', label = 'gaus_1')\n",
    "plt.plot(decel_prob_obj.x, gaus_2,'y', label = 'gaus_2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Velocity_Noise(object):\n",
    "    def __init__(self,t,y):\n",
    "        self.t = t\n",
    "        self.y = y\n",
    "        self.original_y = y\n",
    "        self.original_y_mean = self.original_y.mean()\n",
    "\n",
    "    def subtract_avg(self):\n",
    "        \"\"\"Removes the average speed from the observations\n",
    "        \"\"\"\n",
    "        self.y = self.y - self.original_y_mean\n",
    "        return self.y\n",
    "\n",
    "    def subtract(self, array):\n",
    "        self.y = self.y - array\n",
    "        return self.y\n",
    "\n",
    "    def single_component(self, A_i_FS, w_i_FS, phi_i_FS):\n",
    "        \"\"\" Returns a single velocity noise component as described in the sum of eqn (5)\n",
    "        \"\"\"\n",
    "        return A_i_FS * np.sin( (w_i_FS*self.t) + phi_i_FS )\n",
    "     \n",
    "    def eqn_model(self, params):\n",
    "        \"\"\" Returns the velocity noise FS model as described in eqn (5)\n",
    "        \"\"\"\n",
    "        # put all the paramters in a list\n",
    "        A_FS = [params['A1_FS'],params['A2_FS'],params['A3_FS']]\n",
    "        w_FS = [params['w1_FS'],params['w2_FS'],params['w3_FS']]\n",
    "        phi_FS = [params['phi1_FS'],params['phi2_FS'],params['phi3_FS']]\n",
    "\n",
    "        # equation (5), sum of 3 components\n",
    "        model = self.single_component(A_FS[0],w_FS[0], phi_FS[0])\n",
    "        model += self.single_component(A_FS[1],w_FS[1], phi_FS[1])\n",
    "        model += self.single_component(A_FS[2],w_FS[2], phi_FS[2])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fnc2min(self, params):\n",
    "        \"\"\" Returns the residuals (eqn 7) for the model for when running all 3 components at once\n",
    "        \"\"\"\n",
    "        return (self.y - self.eqn_model(params))\n",
    "\n",
    "    # def fnc2min(self, params):\n",
    "    #     \"\"\" Returns the residuals (eqn 7) for the model for when running one component at a time\n",
    "    #     \"\"\"\n",
    "    #     return (self.y - self.single_component(params['A_FS'], params['w_FS'], params['phi_FS']))\n",
    "\n",
    "\n",
    "    def NLLSR(self, LMparams):\n",
    "        \"\"\" Returns the result of the NLLSR using LMFit\n",
    "        \"\"\"\n",
    "        # uses least swuares method to minimize the parameters given by LMparams according to the residuals given by self.fnc2min\n",
    "        LMFitmin = Minimizer(self.fnc2min, LMparams)\n",
    "        LMFitResult = LMFitmin.minimize(method='least_squares')\n",
    "        lmfit.printfuncs.report_fit(LMFitResult.params)\n",
    "\n",
    "        return LMFitResult"
   ]
  },
  {
   "source": [
    "class DP(object):\n",
    "    \"\"\" Module 3: Drive Pulse\n",
    "    \"\"\"\n",
    "    def __init__(self,t,y):\n",
    "        # velocity_noise = None\n",
    "        # accel = None\n",
    "        # cruise = None\n",
    "        # decel = None\n",
    "        # idle = None\n",
    "        # t_DP = None\n",
    "        self.t = t\n",
    "        self.y = y\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# The code below is for when we are balancing all 3 components of a Frequency Spectrum (FS) at ONCE\n",
    "## Each block corresponds to one FS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "if __name__ == '__main__':\n",
    "    # loads the csv file\n",
    "    subdir = 'caltrans_processed_drive_cycles/data/1035198_1'\n",
    "    file_name = '2012-05-22.csv'\n",
    "    data = load_csv_data(file_name, subdir)\n",
    "    # get a slice of the data with a relatively long driving pulse\n",
    "    data = data.iloc[1002:1096,:]\n",
    "    # show the slice of data\n",
    "    plt.plot(data.loc[:,'timestamp'], data.loc[:,'speed_mph'])\n",
    "    plt.show()\n",
    "    # get the slice of ONLY cruising period\n",
    "    cruising_data = data.iloc[25:86,:]\n",
    "\n",
    "    # create a numpy array of just t values starting at t=1\n",
    "    t = np.linspace(1,len(cruising_data),len(cruising_data))\n",
    "    # create a numpy array of speed_mph values\n",
    "    y = cruising_data.loc[:,'speed_mph'].to_numpy()\n",
    "    # initialise the DP object\n",
    "    vn_obj = Velocity_Noise(t,y)\n",
    "    # deduct the average from the cruising period speed values (from fig3a to fig3b) and store as y\n",
    "    y = vn_obj.subtract_avg()\n",
    "\n",
    "    original_y = y\n",
    "    \n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(LF_Noise())\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = hi.params['A1_FS'] * np.sin( (hi.params['w1_FS']*t) + hi.params['phi1_FS'])\n",
    "    yy = yy + hi.params['A2_FS'] * np.sin( (hi.params['w2_FS']*t) + hi.params['phi2_FS'])\n",
    "    yy = yy + hi.params['A3_FS'] * np.sin( (hi.params['w3_FS']*t) + hi.params['phi3_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed = yy\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi2 = vn_obj.NLLSR(MF_Noise())\n",
    "\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = hi2.params['A1_FS'] * np.sin( (hi2.params['w1_FS']*t) + hi2.params['phi1_FS'])\n",
    "    yy = yy + hi2.params['A2_FS'] * np.sin( (hi2.params['w2_FS']*t) + hi2.params['phi2_FS'])\n",
    "    yy = yy + hi2.params['A3_FS'] * np.sin( (hi2.params['w3_FS']*t) + hi2.params['phi3_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi3 = vn_obj.NLLSR(HF_Noise())\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = hi3.params['A1_FS'] * np.sin( (hi3.params['w1_FS']*t) + hi3.params['phi1_FS'])\n",
    "    yy = yy + hi3.params['A2_FS'] * np.sin( (hi3.params['w2_FS']*t) + hi3.params['phi2_FS'])\n",
    "    yy = yy + hi3.params['A3_FS'] * np.sin( (hi3.params['w3_FS']*t) + hi3.params['phi3_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')hd t5 .\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    plt.plot(t,original_y,'b')\n",
    "    plt.plot(t, reconstructed,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "source": [
    "# The code below is for when we are running one component at once \n",
    "## Each block is for one Frequency Spectrum"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # loads the csv file\n",
    "    subdir = 'caltrans_processed_drive_cycles/data/1035198_1'\n",
    "    file_name = '2012-05-22.csv'\n",
    "    data = load_csv_data(file_name, subdir)\n",
    "    # get a slice of the data with a relatively long driving pulse\n",
    "    data = data.iloc[1002:1096,:]\n",
    "    plt.plot(data.loc[:,'timestamp'], data.loc[:,'speed_mph'])\n",
    "    plt.show()\n",
    "    # get the slice of ONLY cruising period\n",
    "    cruising_data = data.iloc[25:86,:]\n",
    "\n",
    "    # create a numpy array of just t values starting at t=1\n",
    "    t = np.linspace(1,len(cruising_data),len(cruising_data))\n",
    "    # create a numpy array of speed_mph values\n",
    "    y = cruising_data.loc[:,'speed_mph'].to_numpy()\n",
    "    # initialise the DP object\n",
    "    vn_obj = Velocity_Noise(t,y)\n",
    "    # deduct the average from the cruising period speed values (from fig3a to fig3b) and store as y\n",
    "    y = vn_obj.subtract_avg()\n",
    "\n",
    "    original_y = y\n",
    "    \n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(LF_Noise(1))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed = yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(LF_Noise(2))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(LF_Noise(3))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(MF_Noise(1))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of MF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(MF_Noise(2))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of MF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(MF_Noise(3))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of MF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(HF_Noise(1))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of HF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(HF_Noise(2))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of HF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(HF_Noise(3))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of HF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    plt.plot(t,original_y,'b')\n",
    "    plt.plot(t, reconstructed,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n"
   ]
  }
 ]
}